{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "\r\n",
        "# check core SDK version number\r\n",
        "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1625414597088
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.random import set_seed"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414599465
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414599539
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414600115
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name = 'tveer-training'\r\n",
        "\r\n",
        "from azureml.core import Experiment\r\n",
        "exp = Experiment(workspace=ws, name=experiment_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414600797
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_folder = os.path.join(os.getcwd(), \"ai-training\")\r\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414600949
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import tensorflow.keras\r\n",
        "from tensorflow.keras.layers import Flatten, Input, concatenate, Dense, Activation, Dropout, BatchNormalization,  MaxPooling2D, AveragePooling2D, Conv2D\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.applications import VGG19\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\r\n",
        "\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "\r\n",
        "from numpy.random import seed\r\n",
        "seed(1)\r\n",
        "from tensorflow.random import set_seed\r\n",
        "set_seed(2)\r\n",
        "\r\n",
        "# let user feed in 4 parameters:\r\n",
        "# the datasets of the generated and test data (mount or download);\r\n",
        "# the amount of epochs to train;\r\n",
        "# the batch size to train;\r\n",
        "# The model name\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument('--data-folder', type=str, dest='data_folder', help='Test data folder mounting point')\r\n",
        "parser.add_argument('--epochs', type=str, dest='epochs', help='Amount of epochs to train')\r\n",
        "parser.add_argument('--batch_size', type=str, dest='batch_size', help='Batch size')\r\n",
        "parser.add_argument('--model_name', type=str, dest='model_name', help='Model name')\r\n",
        "args = parser.parse_args()\r\n",
        "\r\n",
        "\r\n",
        "data_folder = args.data_folder\r\n",
        "print('Data folder:', data_folder)\r\n",
        "\r\n",
        "X_test_conv = np.load(os.path.join(data_folder, 'X_test_conv.npy'))\r\n",
        "X_test_values = np.load(os.path.join(data_folder, 'X_test_values.npy'))\r\n",
        "y_test = np.load(os.path.join(data_folder, 'y_test.npy'))\r\n",
        "\r\n",
        "X_train_conv = np.load(os.path.join(data_folder, 'X_train_conv_generated.npy'))\r\n",
        "X_train_values = np.load(os.path.join(data_folder, 'X_train_values_generated.npy'))\r\n",
        "y_train = np.load(os.path.join(data_folder, 'y_train_generated.npy'))\r\n",
        "\r\n",
        "print(X_test_conv.shape, X_test_values.shape, y_test.shape, sep = '\\n')\r\n",
        "print(X_train_conv.shape, X_train_values.shape, y_train.shape, sep = '\\n')\r\n",
        "\r\n",
        "labels = np.load(os.path.join(data_folder, 'component_names.npy')).tolist()\r\n",
        "print(f\"Labels: {labels}\")\r\n",
        "\r\n",
        "# get hold of the current run\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# Neural network\r\n",
        "batch_size = int(args.batch_size)\r\n",
        "epochs = int(args.epochs)\r\n",
        "X_conv = Input(shape=(64, 64, 3))\r\n",
        "\r\n",
        "vgg_model = VGG19(include_top=False, weights='imagenet')(X_conv)    # Add all the layers of the VGG19 model\r\n",
        "\r\n",
        "x_1 = Flatten(name='flatten')(vgg_model)\r\n",
        "x_1 = Dense(512, activation='relu', name='fully-connected-1')(x_1)\r\n",
        "x_1 = Dense(512, activation='relu', name='fully-connected-2')(x_1)\r\n",
        "\r\n",
        "X_extra = Input(shape=(1,))\r\n",
        "\r\n",
        "combined = concatenate([x_1, X_extra]) ## Combined input\r\n",
        "x_2 = Dense(16, activation='relu', name='combined-fully-connected-1')(combined)\r\n",
        "## Output\r\n",
        "x_2 = Dense(y_test.shape[1], activation='softmax', name='combined-fully-connected-2')(x_2)\r\n",
        "\r\n",
        "final_model = Model(inputs=[X_conv, X_extra], outputs=x_2)\r\n",
        "\r\n",
        "opt = tensorflow.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0, clipvalue=0.6)\r\n",
        "\r\n",
        "final_model.compile(optimizer=opt, loss='categorical_crossentropy', \r\n",
        "                   metrics=['accuracy'])\r\n",
        "\r\n",
        "early_stopping_callback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)\r\n",
        "reduce_lr = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1)\r\n",
        "\r\n",
        "\r\n",
        "history = final_model.fit([X_train_conv, X_train_values],\r\n",
        "                            y_train,\r\n",
        "                            validation_data=([X_test_conv, X_test_values], y_test),\r\n",
        "                            epochs = epochs,\r\n",
        "                            batch_size = batch_size, # x * batch_size == amount of data in one epoch\r\n",
        "                            verbose = 1,\r\n",
        "                            shuffle=True,\r\n",
        "                            workers=1,\r\n",
        "                            callbacks=[reduce_lr]\r\n",
        "                        )\r\n",
        "\r\n",
        "print('Predict the test set')\r\n",
        "predictions = final_model.predict([X_test_conv, X_test_values])\r\n",
        "predictions = predictions.argmax(axis=1)\r\n",
        "\r\n",
        "class_report = classification_report(y_test.argmax(axis=1), predictions, target_names=labels)\r\n",
        "run.log(\"Classification report\", class_report)\r\n",
        "\r\n",
        "cf = confusion_matrix(y_test.argmax(axis=1), predictions)\r\n",
        "# run.log_confusion_matrix(\"Confusion Matrix\", cf)\r\n",
        "run.log(\"Confusion matrix\", cf)\r\n",
        "\r\n",
        "acc = accuracy_score(y_test.argmax(axis=1), predictions) * 100\r\n",
        "\r\n",
        "\r\n",
        "run.log('accuracy', np.float(acc))\r\n",
        "run.log(\"Epochs:\", epochs)\r\n",
        "run.log(\"batch_size\", batch_size)\r\n",
        "\r\n",
        "run.log_list(\"Accuracy\", history.history['accuracy'])\r\n",
        "run.log_list(\"Validation accuracy\", history.history['val_accuracy'])\r\n",
        "run.log_list(\"Loss\", history.history['loss'])\r\n",
        "run.log_list(\"Validation loss\", history.history['val_loss'])\r\n",
        "\r\n",
        "os.makedirs('outputs', exist_ok=True)\r\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\r\n",
        "final_model.save(f\"outputs/{str(args.model_name)}\")\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.environment import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "# to install required packages\r\n",
        "env = Environment('tveer-training-env')\r\n",
        "cd = CondaDependencies.create(\r\n",
        "    pip_packages=['azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults', 'tensorflow', 'scikit-learn'],\r\n",
        "    )\r\n",
        "\r\n",
        "env.python.conda_dependencies = cd\r\n",
        "\r\n",
        "# Register environment to re-use later\r\n",
        "env.register(workspace = ws)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414601321
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\r\n",
        "from azureml.core.compute import ComputeTarget\r\n",
        "import os\r\n",
        "\r\n",
        "# choose a name for your cluster\r\n",
        "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"tveer-cluster-2\")\r\n",
        "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\r\n",
        "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 1)\r\n",
        "\r\n",
        "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\r\n",
        "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"Standard_D4_v2\")\r\n",
        "\r\n",
        "\r\n",
        "if compute_name in ws.compute_targets:\r\n",
        "    compute_target = ws.compute_targets[compute_name]\r\n",
        "    if compute_target and type(compute_target) is AmlCompute:\r\n",
        "        print(\"found compute target: \" + compute_name)\r\n",
        "else:\r\n",
        "    print(\"creating new compute target...\")\r\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\r\n",
        "                                                                min_nodes = compute_min_nodes, \r\n",
        "                                                                max_nodes = compute_max_nodes)\r\n",
        "\r\n",
        "    # create the cluster\r\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\r\n",
        "    \r\n",
        "    # can poll for a minimum number of nodes and for a specific timeout. \r\n",
        "    # if no min node count is provided it will use the scale settings for the cluster\r\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\r\n",
        "    \r\n",
        "     # For a more detailed view of current AmlCompute status, use get_status()\r\n",
        "    print(compute_target.get_status().serialize())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414634267
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414634400
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_dataset = Dataset.get_by_name(ws, name='train_test_dataset')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414638390
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import ScriptRunConfig\r\n",
        "model_name = \"tveer-model\"\r\n",
        "args = ['--data-folder', train_test_dataset.as_mount(), '--epochs', 30, '--batch_size', 32, '--model_name', model_name]\r\n",
        "\r\n",
        "src = ScriptRunConfig(source_directory=script_folder,\r\n",
        "                      script='train.py', \r\n",
        "                      arguments=args,\r\n",
        "                      compute_target=compute_target,\r\n",
        "                      environment=env)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414638538
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src.arguments"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414638679
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = exp.submit(config=src)\r\n",
        "run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414641735
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\r\n",
        "RunDetails(run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414643095
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625414643174
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run.wait_for_completion()\r\n",
        "\r\n",
        "run_details = {k:v for k,v in run.get_details().items() if k not in ['inputDatasets', 'outputDatasets']}\r\n",
        "\r\n",
        "with open('states/training-run.json', 'w') as training_run_json:\r\n",
        "    json.dump(run_details, training_run_json)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625418542545
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = run.register_model(model_name='tveer-model', model_path=f'outputs/{model_name}')\r\n",
        "print(model.name, model.id, model.version, sep='\\t')\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625418546889
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = {}\r\n",
        "model_json[\"model\"] = model.serialize()\r\n",
        "model_json[\"run\"] = run_details\r\n",
        "\r\n",
        "with open('states/model_details.json', 'w') as model_details:\r\n",
        "    json.dump(model_json, model_details)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1625418547381
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}